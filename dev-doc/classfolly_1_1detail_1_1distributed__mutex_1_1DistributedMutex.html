<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>autotier: folly::detail::distributed_mutex::DistributedMutex&lt; Atomic, TimePublishing &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">autotier
   </div>
   <div id="projectbrief">Automatic Tiering Fuse Filesystem</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>folly</b></li><li class="navelem"><b>detail</b></li><li class="navelem"><b>distributed_mutex</b></li><li class="navelem"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">folly::detail::distributed_mutex::DistributedMutex&lt; Atomic, TimePublishing &gt; Class Template Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="DistributedMutex_8h_source.html">DistributedMutex.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:aea758280455d5d54df56c2fa1919e4bf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#aea758280455d5d54df56c2fa1919e4bf">DistributedMutex</a> ()</td></tr>
<tr class="separator:aea758280455d5d54df56c2fa1919e4bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dfd0b66b737e422b421312db1bb8e73"><td class="memItemLeft" align="right" valign="top"><a id="a1dfd0b66b737e422b421312db1bb8e73"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DistributedMutex</b> (<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;&amp;)=delete</td></tr>
<tr class="separator:a1dfd0b66b737e422b421312db1bb8e73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4da9faea0adb3a15068784df2aea131"><td class="memItemLeft" align="right" valign="top"><a id="af4da9faea0adb3a15068784df2aea131"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>DistributedMutex</b> (const <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;)=delete</td></tr>
<tr class="separator:af4da9faea0adb3a15068784df2aea131"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6b75c245d2b24db544e990de0e09002"><td class="memItemLeft" align="right" valign="top"><a id="ac6b75c245d2b24db544e990de0e09002"></a>
<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator=</b> (<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;&amp;)=delete</td></tr>
<tr class="separator:ac6b75c245d2b24db544e990de0e09002"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a354432cf32bcaf408febec14d6c0303c"><td class="memItemLeft" align="right" valign="top"><a id="a354432cf32bcaf408febec14d6c0303c"></a>
<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><b>operator=</b> (const <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> &amp;)=delete</td></tr>
<tr class="separator:a354432cf32bcaf408febec14d6c0303c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85c5d1b40693aa78f4d57f97a9cdea25"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a85c5d1b40693aa78f4d57f97a9cdea25">lock</a> ()</td></tr>
<tr class="separator:a85c5d1b40693aa78f4d57f97a9cdea25"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac64302904ce02bc0f284cff945ea4f87"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ac64302904ce02bc0f284cff945ea4f87">unlock</a> (<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>)</td></tr>
<tr class="separator:ac64302904ce02bc0f284cff945ea4f87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acf4f202428ece047e471c81c2d6920ed"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#acf4f202428ece047e471c81c2d6920ed">try_lock</a> ()</td></tr>
<tr class="separator:acf4f202428ece047e471c81c2d6920ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1a3d59dfd50175ad8de0d0ed97d34f9"><td class="memTemplParams" colspan="2">template&lt;typename Rep , typename Period &gt; </td></tr>
<tr class="memitem:ad1a3d59dfd50175ad8de0d0ed97d34f9"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ad1a3d59dfd50175ad8de0d0ed97d34f9">try_lock_for</a> (const std::chrono::duration&lt; Rep, Period &gt; &amp;duration)</td></tr>
<tr class="separator:ad1a3d59dfd50175ad8de0d0ed97d34f9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a833e91611ebf3e222d9ea77c288a5d3c"><td class="memTemplParams" colspan="2">template&lt;typename Clock , typename Duration &gt; </td></tr>
<tr class="memitem:a833e91611ebf3e222d9ea77c288a5d3c"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a833e91611ebf3e222d9ea77c288a5d3c">try_lock_until</a> (const std::chrono::time_point&lt; Clock, Duration &gt; &amp;deadline)</td></tr>
<tr class="separator:a833e91611ebf3e222d9ea77c288a5d3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9870e8ffbfa7851f4512c24ccb8c57eb"><td class="memTemplParams" colspan="2">template&lt;typename Task &gt; </td></tr>
<tr class="memitem:a9870e8ffbfa7851f4512c24ccb8c57eb"><td class="memTemplItemLeft" align="right" valign="top">auto&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a9870e8ffbfa7851f4512c24ccb8c57eb">lock_combine</a> (Task task) -&gt; decltype(std::declval&lt; const Task &amp; &gt;()())</td></tr>
<tr class="separator:a9870e8ffbfa7851f4512c24ccb8c57eb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a890dc44b5e96af37aecff3a5edeeb532"><td class="memTemplParams" colspan="2"><a id="a890dc44b5e96af37aecff3a5edeeb532"></a>
template&lt;typename Func &gt; </td></tr>
<tr class="memitem:a890dc44b5e96af37aecff3a5edeeb532"><td class="memTemplItemLeft" align="right" valign="top">auto&#160;</td><td class="memTemplItemRight" valign="bottom"><b>lock_combine</b> (Func func) -&gt; decltype(std::declval&lt; const Func &amp; &gt;()())</td></tr>
<tr class="separator:a890dc44b5e96af37aecff3a5edeeb532"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a068b1e6f8cd70e544be2f25f39632529"><td class="memItemLeft" align="right" valign="top"><a id="a068b1e6f8cd70e544be2f25f39632529"></a>
Atomic&lt; std::uintptr_t &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>state_</b> {0}</td></tr>
<tr class="separator:a068b1e6f8cd70e544be2f25f39632529"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;template&lt; typename &gt; class Atomic = std::atomic, bool TimePublishing = true&gt;<br />
class folly::detail::distributed_mutex::DistributedMutex&lt; Atomic, TimePublishing &gt;</h3>

<p><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> is a small, exclusive-only mutex that distributes the bookkeeping required for mutual exclusion in the stacks of threads that are contending for it. It has a mode that can combine critical sections when the mutex experiences contention; this allows the implementation to elide several expensive coherence and synchronization operations to boost throughput, surpassing even atomic instructions in some cases. It has a smaller memory footprint than std::mutex, a similar level of fairness (better in some cases) and no dependencies on heap allocation. It is the same width as a single pointer (8 bytes on most platforms), where on the other hand, std::mutex and pthread_mutex_t are both 40 bytes. It is larger than some of the other smaller locks, but the wide majority of cases using the small locks are wasting the difference in alignment padding anyway</p>
<p>Benchmark results are good - at the time of writing, in the contended case, for lock/unlock based critical sections, it is about 4-5x faster than the smaller locks and about ~2x faster than std::mutex. When used in combinable mode, it is much faster than the alternatives, going more than 10x faster than the small locks, about 6x faster than std::mutex, 2-3x faster than flat combining and even faster than std::atomic&lt;&gt; in some cases, allowing more work with higher throughput. In the uncontended case, it is a few cycles faster than folly::MicroLock but a bit slower than std::mutex. <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> is also resistent to tail latency pathalogies unlike many of the other mutexes in use, which sleep for large time quantums to reduce spin churn, this causes elevated latencies for threads that enter the sleep cycle. The tail latency of lock acquisition can go up to 10x lower because of a more deterministic scheduling algorithm that is managed almost entirely in userspace. Detailed results comparing the throughput and latencies of different mutex implementations and atomics are at the bottom of folly/synchronization/test/SmallLocksBenchmark.cpp</p>
<p>Theoretically, write locks promote concurrency when the critical sections are small as most of the work is done outside the lock. And indeed, performant concurrent applications go through several pains to limit the amount of work they do while holding a lock. However, most times, the synchronization and scheduling overhead of a write lock in the critical path is so high, that after a certain point, making critical sections smaller does not actually increase the concurrency of the application and throughput plateaus. <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> moves this breaking point to the level of hardware atomic instructions, so applications keep getting concurrency even under very high contention. It does this by reducing cache misses and contention in userspace and in the kernel by making each thread wait on a thread local node and futex. When combined critical sections are used <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> leverages template metaprogramming to allow the mutex to make better synchronization decisions based on the layout of the input and output data. This allows threads to keep working only on their own cache lines without requiring cache coherence operations when a mutex experiences heavy contention</p>
<p>Non-timed mutex acquisitions are scheduled through intrusive LIFO contention chains. Each thread starts by spinning for a short quantum and falls back to two phased sleeping. Enqueue operations are lock free and are piggybacked off mutex acquisition attempts. The LIFO behavior of a contention chain is good in the case where the mutex is held for a short amount of time, as the head of the chain is likely to not have slept on futex() after exhausting its spin quantum. This allow us to avoid unnecessary traversal and syscalls in the fast path with a higher probability. Even though the contention chains are LIFO, the mutex itself does not adhere to that scheduling policy globally. During contention, threads that fail to lock the mutex form a LIFO chain on the central mutex state, this chain is broken when a wakeup is scheduled, and future enqueue operations form a new chain. This makes the chains themselves LIFO, but preserves global fairness through a constant factor which is limited to the number of concurrent failed mutex acquisition attempts. This binds the last in first out behavior to the number of contending threads and helps prevent starvation and latency outliers</p>
<p>This strategy of waking up wakers one by one in a queue does not scale well when the number of threads goes past the number of cores. At which point preemption causes elevated lock acquisition latencies. <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> implements a hardware timestamp publishing heuristic to detect and adapt to preemption.</p>
<p><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> does not have the typical mutex API - it does not satisfy the Lockable concept. It requires the user to maintain ephemeral bookkeeping and pass that bookkeeping around to <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ac64302904ce02bc0f284cff945ea4f87">unlock()</a> calls. The API overhead, however, comes for free when you wrap this mutex for usage with std::unique_lock, which is the recommended usage (std::lock_guard, in optimized mode, has no performance benefit over std::unique_lock, so has been omitted). A benefit of this API is that it disallows incorrect usage where a thread unlocks a mutex that it does not own, thinking a mutex is functionally identical to a binary semaphore, which, unlike a mutex, is a suitable primitive for that usage</p>
<p>Combined critical sections allow the implementation to elide several expensive operations during the lifetime of a critical section that cause slowdowns with regular lock/unlock based usage. <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> resolves contention through combining up to a constant factor of 2 contention chains to prevent issues with fairness and latency outliers, so we retain the fairness benefits of the lock/unlock implementation with no noticeable regression when switching between the lock methods. Despite the efficiency benefits, combined critical sections can only be used when the critical section does not depend on thread local state and does not introduce new dependencies between threads when the critical section gets combined. For example, locking or unlocking an unrelated mutex in a combined critical section might lead to unexpected results or even undefined behavior. This can happen if, for example, a different thread unlocks a mutex locked by the calling thread, leading to undefined behavior as the mutex might not allow locking and unlocking from unrelated threads (the posix and C++ standard disallow this usage for their mutexes)</p>
<p>Timed locking through <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> is implemented through a centralized algorithm. The underlying contention-chains framework used in <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> is not abortable so we build abortability on the side. All waiters wait on the central mutex state, by setting and resetting bits within the pointer-length word. Since pointer length atomic integers are incompatible with futex(FUTEX_WAIT) on most systems, a non-standard implementation of futex() is used, where wait queues are managed in user-space (see p1135r0 and <a class="el" href="classfolly_1_1ParkingLot.html">folly::ParkingLot</a> for more) </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="aea758280455d5d54df56c2fa1919e4bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea758280455d5d54df56c2fa1919e4bf">&#9670;&nbsp;</a></span>DistributedMutex()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool TimePublishing&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a></td>
        </tr>
      </table>
</div><div class="memdoc">
<p><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a> is only default constructible, it can neither be moved nor copied </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a85c5d1b40693aa78f4d57f97a9cdea25"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85c5d1b40693aa78f4d57f97a9cdea25">&#9670;&nbsp;</a></span>lock()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool TimePublishing&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a> <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::lock</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Acquires the mutex in exclusive mode</p>
<p>This returns an ephemeral proxy that contains internal mutex state. This must be kept around for the duration of the critical section and passed subsequently to <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ac64302904ce02bc0f284cff945ea4f87">unlock()</a> as an rvalue</p>
<p>The proxy has no public API and is intended to be for internal usage only</p>
<p>There are three notable cases where this method causes undefined behavior:</p>
<ul>
<li>This is not a recursive mutex. Trying to acquire the mutex twice from the same thread without unlocking it results in undefined behavior</li>
<li>Thread, coroutine or fiber migrations from within a critical section are disallowed. This is because the implementation requires owning the stack frame through the execution of the critical section for both lock/unlock or combined critical sections. This also means that you cannot allow another thread, fiber or coroutine to unlock the mutex</li>
<li>This mutex cannot be used in a program compiled with segmented stacks, there is currently no way to detect the presence of segmented stacks at compile time or runtime, so we have no checks against this </li>
</ul>

</div>
</div>
<a id="a9870e8ffbfa7851f4512c24ccb8c57eb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9870e8ffbfa7851f4512c24ccb8c57eb">&#9670;&nbsp;</a></span>lock_combine()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic = std::atomic, bool TimePublishing = true&gt; </div>
<div class="memtemplate">
template&lt;typename Task &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::lock_combine </td>
          <td>(</td>
          <td class="paramtype">Task&#160;</td>
          <td class="paramname"><em>task</em></td><td>)</td>
          <td> -&gt;  decltype(std::declval&lt; const Task &amp; &gt;()())</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Execute a task as a combined critical section</p>
<p>Unlike traditional lock and unlock methods, <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a9870e8ffbfa7851f4512c24ccb8c57eb">lock_combine()</a> enqueues the passed task for execution on any arbitrary thread. This allows the implementation to prevent cache line invalidations originating from expensive synchronization operations. The thread holding the lock is allowed to execute the task before unlocking, thereby forming a "combined
critical section".</p>
<p>This idea is inspired by Flat Combining. Flat Combining was introduced in the SPAA 2010 paper titled "Flat Combining and the
Synchronization-Parallelism Tradeoff", by Danny Hendler, Itai Incze, Nir Shavit, and Moran Tzafrir - <a href="https://www.cs.bgu.ac.il/~hendlerd/papers/flat-combining.pdf">https://www.cs.bgu.ac.il/~hendlerd/papers/flat-combining.pdf</a>. The implementation used here is significantly different from that described in the paper. The high-level goal of reducing the overhead of synchronization, however, is the same.</p>
<p>Combined critical sections work best when kept simple. Since the critical section might be executed on any arbitrary thread, relying on things like thread local state or mutex locking and unlocking might cause incorrectness. Associativity is important. For example</p>
<p>auto one = std::unique_lock{one_}; two_.lock_combine([&amp;]() { if (bar()) { one.unlock(); } });</p>
<p>This has the potential to cause undefined behavior because mutexes are only meant to be acquired and released from the owning thread. Similar errors can arise from a combined critical section introducing implicit dependencies based on the state of the combining thread. For example</p>
<p>// thread 1 auto one = std::unique_lock{one_}; auto two = std::unique_lock{two_};</p>
<p>// thread 2 two_.lock_combine([&amp;]() { auto three = std::unique_lock{three_}; });</p>
<p>Here, because we used a combined critical section, we have introduced a dependency from one -&gt; three that might not obvious to the reader</p>
<p>This function is exception-safe. If the passed task throws an exception, it will be propagated to the caller, even if the task is running on another thread</p>
<p>There are three notable cases where this method causes undefined behavior:</p>
<ul>
<li>This is not a recursive mutex. Trying to acquire the mutex twice from the same thread without unlocking it results in undefined behavior</li>
<li>Thread, coroutine or fiber migrations from within a critical section are disallowed. This is because the implementation requires owning the stack frame through the execution of the critical section for both lock/unlock or combined critical sections. This also means that you cannot allow another thread, fiber or coroutine to unlock the mutex</li>
<li>This mutex cannot be used in a program compiled with segmented stacks, there is currently no way to detect the presence of segmented stacks at compile time or runtime, so we have no checks against this </li>
</ul>

</div>
</div>
<a id="acf4f202428ece047e471c81c2d6920ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acf4f202428ece047e471c81c2d6920ed">&#9670;&nbsp;</a></span>try_lock()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool TimePublishing&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a> <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::try_lock</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Try to acquire the mutex</p>
<p>A non blocking version of the <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a85c5d1b40693aa78f4d57f97a9cdea25">lock()</a> function. The returned object is contextually convertible to bool. And has the value true when the mutex was successfully acquired, false otherwise</p>
<p>This is allowed to return false spuriously, i.e. this is not guaranteed to return true even when the mutex is currently unlocked. In the event of a failed acquisition, this does not impose any memory ordering constraints for other threads </p>

</div>
</div>
<a id="ad1a3d59dfd50175ad8de0d0ed97d34f9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1a3d59dfd50175ad8de0d0ed97d34f9">&#9670;&nbsp;</a></span>try_lock_for()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool TimePublishing&gt; </div>
<div class="memtemplate">
template&lt;typename Rep , typename Period &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a> <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::try_lock_for </td>
          <td>(</td>
          <td class="paramtype">const std::chrono::duration&lt; Rep, Period &gt; &amp;&#160;</td>
          <td class="paramname"><em>duration</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Try to acquire the mutex, blocking for the given time</p>
<p>Like <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#acf4f202428ece047e471c81c2d6920ed">try_lock()</a>, this is allowed to fail spuriously and is not guaranteed to return false even when the mutex is currently unlocked. But only after the given time has elapsed</p>
<p><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ad1a3d59dfd50175ad8de0d0ed97d34f9">try_lock_for()</a> accepts a duration to block for, and <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#a833e91611ebf3e222d9ea77c288a5d3c">try_lock_until()</a> accepts an absolute wall clock time point </p>

</div>
</div>
<a id="a833e91611ebf3e222d9ea77c288a5d3c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a833e91611ebf3e222d9ea77c288a5d3c">&#9670;&nbsp;</a></span>try_lock_until()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool TimePublishing&gt; </div>
<div class="memtemplate">
template&lt;typename Clock , typename Duration &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a> <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::try_lock_until </td>
          <td>(</td>
          <td class="paramtype">const std::chrono::time_point&lt; Clock, Duration &gt; &amp;&#160;</td>
          <td class="paramname"><em>deadline</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Try to acquire the lock, blocking until the given deadline</p>
<p>Other than the difference in the meaning of the second argument, the semantics of this function are identical to <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html#ad1a3d59dfd50175ad8de0d0ed97d34f9">try_lock_for()</a> </p>

</div>
</div>
<a id="ac64302904ce02bc0f284cff945ea4f87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac64302904ce02bc0f284cff945ea4f87">&#9670;&nbsp;</a></span>unlock()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;template&lt; typename &gt; class Atomic, bool Publish&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">folly::detail::distributed_mutex::DistributedMutex</a>&lt; Atomic, Publish &gt;::unlock </td>
          <td>(</td>
          <td class="paramtype">typename <a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex.html">DistributedMutex</a>&lt; Atomic, TimePublishing &gt;::<a class="el" href="classfolly_1_1detail_1_1distributed__mutex_1_1DistributedMutex_1_1DistributedMutexStateProxy.html">DistributedMutexStateProxy</a>&#160;</td>
          <td class="paramname"><em>proxy</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Unlocks the mutex</p>
<p>The proxy returned by lock must be passed to unlock as an rvalue. No other option is possible here, since the proxy is only movable and not copyable</p>
<p>It is undefined behavior to unlock from a thread that did not lock the mutex </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>src/rocksdb/third-party/folly/folly/synchronization/<a class="el" href="DistributedMutex_8h_source.html">DistributedMutex.h</a></li>
<li>src/rocksdb/third-party/folly/folly/synchronization/<a class="el" href="DistributedMutex-inl_8h_source.html">DistributedMutex-inl.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
